{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0+cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.2577e-27,  8.0014e-43, -2.2577e-27],\n",
      "        [ 8.0014e-43, -1.0465e-26,  8.0014e-43],\n",
      "        [-1.0477e-26,  8.0014e-43, -1.0859e-26],\n",
      "        [ 8.0014e-43, -5.6021e-27,  8.0014e-43],\n",
      "        [-5.5999e-27,  8.0014e-43, -5.5999e-27],\n",
      "        [ 8.0014e-43, -1.0850e-26,  8.0014e-43]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.empty(6,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7945, 0.0252, 0.7739],\n",
      "        [0.6521, 0.0206, 0.2088],\n",
      "        [0.6202, 0.7565, 0.3125],\n",
      "        [0.2163, 0.4197, 0.8613]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(4,3, dtype=torch.long)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch expects always numerical values but not strings\n",
    "a = torch.tensor([7.8,5])\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.8000, 5.0000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 2.4825,  0.0905,  0.6765, -0.0592,  0.5039],\n",
      "        [-1.0823, -0.3050, -1.0890, -1.4767, -1.5256],\n",
      "        [-0.4688,  0.2568,  0.0660,  1.0743, -0.2290],\n",
      "        [ 0.4706, -0.0541,  0.2365, -0.5373, -0.9655],\n",
      "        [ 0.0945,  2.0391,  0.5677,  0.8686,  1.8126]])\n"
     ]
    }
   ],
   "source": [
    "#override the previous ize of the tensors\n",
    "a=a.new_ones(5,5, dtype = torch.double)\n",
    "print(a)\n",
    "\n",
    "a = torch.randn_like(a, dtype = torch.float)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.3566,  0.9450,  0.6516, -0.4599, -0.3498],\n",
      "        [-1.2579, -0.8106, -2.0951, -0.8258, -2.4736],\n",
      "        [-0.9787, -0.0728,  1.3333,  0.3574,  1.0224],\n",
      "        [ 1.0329, -0.6899, -0.6708,  0.1706, -0.6920],\n",
      "        [ 1.6122,  1.1947,  1.1040,  0.1058,  1.9891]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.randn(5,5)\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.3566,  0.9450,  0.6516, -0.4599, -0.3498],\n",
      "        [-1.2579, -0.8106, -2.0951, -0.8258, -2.4736],\n",
      "        [-0.9787, -0.0728,  1.3333,  0.3574,  1.0224],\n",
      "        [ 1.0329, -0.6899, -0.6708,  0.1706, -0.6920],\n",
      "        [ 1.6122,  1.1947,  1.1040,  0.1058,  1.9891]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5,5)\n",
    "torch.add(a,b, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.3566,  0.9450,  0.6516, -0.4599, -0.3498],\n",
      "        [-1.2579, -0.8106, -2.0951, -0.8258, -2.4736],\n",
      "        [-0.9787, -0.0728,  1.3333,  0.3574,  1.0224],\n",
      "        [ 1.0329, -0.6899, -0.6708,  0.1706, -0.6920],\n",
      "        [ 1.6122,  1.1947,  1.1040,  0.1058,  1.9891]])\n"
     ]
    }
   ],
   "source": [
    "b.add_(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0905)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6765, -1.0890,  0.0660,  0.2365,  0.5677])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(3,3)\n",
    "b = a.view(9)\n",
    "c = a.view(-1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3]) torch.Size([9]) torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "print(a.size(),b.size(),c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9618174433708191"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.numpy()\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2.])\n",
      "[2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "x.add_(1)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 4. 4. 4.]\n",
      "tensor([4., 4., 4., 4.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "f = np.ones(4)\n",
    "g = torch.from_numpy(f)\n",
    "np.add(f,3, out=f)\n",
    "print(f)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us run this cell only if CUDA is available\n",
    "#we will use \"torch.device\" objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y= torch.ones_like(x, device=device)\n",
    "    x=x.to(device)\n",
    "    z= x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOGRAD: Automatic Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2,2, requires_grad=True)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "b = a+2\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x0000023B969D9D48>\n"
     ]
    }
   ],
   "source": [
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "c = b * b * 3\n",
    "out = c.mean()\n",
    "print(c, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x0000023B969C59C8>\n"
     ]
    }
   ],
   "source": [
    "p=torch.rand(3,3)\n",
    "p = ((p*3)/(p-1))\n",
    "print(p.requires_grad)\n",
    "p.requires_grad_(True)\n",
    "print(p.requires_grad)\n",
    "q = (p*p).sum()\n",
    "print(q.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rkocherlakota\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "out.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5000, 4.5000],\n",
       "        [4.5000, 4.5000]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  15.5942, -596.5112,  973.8916], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad= True)\n",
    "y = x*2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 204.8000, 2048.0000,    2.0480])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1,1.0,0.001], dtype = torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(network,self).__init__()\n",
    "        #1 input image channel, 6 output channels and 3X3 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1,6,3)\n",
    "        self.conv2 = nn.Conv2d(6,16,3)\n",
    "        #an affine operation: y= mx+c\n",
    "        self.fc1 = nn.Linear(16*6*6,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #Max pooling layer of size (2,2)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        #if size is a square you only specify a single number \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = x.view(-1,self.num_flat_features(x)) #reset the values by flattening\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        size = x.size()[1:] #all dimensions except batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features*=s\n",
    "        return num_features\n",
    "\n",
    "net = network()            \n",
    "print(net)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[ 0.0055,  0.2000,  0.2227],\n",
      "          [-0.0233,  0.0025,  0.0775],\n",
      "          [-0.0191,  0.0964, -0.2992]]],\n",
      "\n",
      "\n",
      "        [[[-0.2746,  0.1286, -0.0219],\n",
      "          [-0.1913, -0.0352,  0.0271],\n",
      "          [ 0.2517,  0.1299, -0.2052]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2534,  0.2669, -0.3150],\n",
      "          [-0.0830, -0.1725, -0.2842],\n",
      "          [-0.0925, -0.0426, -0.1237]]],\n",
      "\n",
      "\n",
      "        [[[-0.0815, -0.1028,  0.2731],\n",
      "          [-0.3222,  0.0144, -0.0516],\n",
      "          [ 0.1708, -0.2629, -0.1537]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1882,  0.2756, -0.1468],\n",
      "          [ 0.1427, -0.2444,  0.0314],\n",
      "          [ 0.0844, -0.2161, -0.1978]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2675,  0.2284, -0.2823],\n",
      "          [ 0.0531, -0.2239, -0.0448],\n",
      "          [ 0.2196,  0.0672,  0.0828]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1506,  0.0569,  0.0781,  0.0129,  0.3285,  0.2143],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-6.7017e-02,  8.0972e-02, -1.6347e-02],\n",
      "          [ 2.3753e-02, -1.7492e-02,  9.1682e-02],\n",
      "          [ 4.4082e-02, -4.8371e-02,  1.0537e-01]],\n",
      "\n",
      "         [[-2.0737e-03, -1.2782e-01, -7.7618e-02],\n",
      "          [-3.8012e-02,  5.5129e-02, -1.0198e-01],\n",
      "          [-1.2594e-01, -1.0553e-01,  1.3601e-01]],\n",
      "\n",
      "         [[ 1.1050e-01, -5.8180e-02, -2.0574e-02],\n",
      "          [ 4.5492e-02,  4.3329e-02,  7.8949e-02],\n",
      "          [-6.5235e-03,  5.1582e-02, -1.0824e-01]],\n",
      "\n",
      "         [[-2.7549e-02, -1.1869e-01,  5.2875e-02],\n",
      "          [ 5.2455e-02,  1.0484e-01,  1.0398e-01],\n",
      "          [-8.9394e-02,  5.5355e-02,  6.6259e-02]],\n",
      "\n",
      "         [[ 1.0743e-01,  4.0303e-02,  9.5901e-02],\n",
      "          [ 9.1839e-02, -4.8035e-03,  1.4580e-02],\n",
      "          [ 4.8512e-02, -1.3513e-01, -9.3644e-02]],\n",
      "\n",
      "         [[-9.5297e-02, -9.4753e-02,  4.8953e-02],\n",
      "          [ 1.3407e-01,  1.2524e-01,  9.6353e-02],\n",
      "          [-1.0771e-01, -9.7129e-02, -2.1841e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5628e-02, -3.3112e-02,  1.1801e-01],\n",
      "          [-1.3595e-01, -1.0291e-02,  8.3456e-02],\n",
      "          [-9.7087e-02,  2.5877e-02,  8.6565e-02]],\n",
      "\n",
      "         [[-3.6898e-02,  6.8796e-04, -5.0508e-02],\n",
      "          [-8.7658e-02,  2.5693e-02,  9.7721e-02],\n",
      "          [ 6.0929e-02, -7.1910e-03, -9.7245e-03]],\n",
      "\n",
      "         [[-8.8581e-02, -4.1049e-02, -1.1082e-01],\n",
      "          [-7.1531e-02,  3.6264e-02,  1.9880e-02],\n",
      "          [ 3.8883e-02, -1.0173e-01,  1.3554e-01]],\n",
      "\n",
      "         [[ 3.6647e-03, -9.1648e-02,  7.1562e-02],\n",
      "          [ 1.1660e-01,  5.7842e-02,  1.0151e-01],\n",
      "          [-2.5211e-02,  8.8018e-02, -5.8909e-03]],\n",
      "\n",
      "         [[-2.0620e-02, -5.7462e-02, -2.4750e-03],\n",
      "          [-3.4716e-03, -1.9447e-02,  4.5111e-02],\n",
      "          [-1.3580e-01, -1.3604e-01,  6.2539e-02]],\n",
      "\n",
      "         [[-1.0321e-01, -8.4223e-02,  9.2128e-03],\n",
      "          [ 9.6448e-02, -1.1040e-01, -2.0795e-02],\n",
      "          [ 1.1694e-01, -4.2984e-02,  8.4144e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6423e-03,  1.7138e-02,  5.9117e-02],\n",
      "          [ 1.2436e-01, -1.0915e-01,  1.0845e-01],\n",
      "          [ 2.5533e-02, -1.2372e-01,  6.8541e-02]],\n",
      "\n",
      "         [[ 1.2406e-01, -1.2764e-01, -1.1385e-01],\n",
      "          [-5.8707e-02, -5.5898e-02, -1.0820e-01],\n",
      "          [ 3.2519e-02, -1.5627e-03,  3.2579e-02]],\n",
      "\n",
      "         [[-8.9683e-02, -7.3667e-02,  2.5511e-02],\n",
      "          [ 7.5636e-02,  1.1140e-01,  7.3128e-02],\n",
      "          [-5.9268e-02,  1.8125e-03, -8.8330e-03]],\n",
      "\n",
      "         [[ 1.1379e-01,  3.2853e-02, -8.5422e-02],\n",
      "          [ 6.7758e-02, -3.9621e-02, -6.8996e-02],\n",
      "          [-8.3557e-02,  6.5062e-02, -4.3458e-02]],\n",
      "\n",
      "         [[ 4.4796e-03, -1.0834e-01, -5.7431e-02],\n",
      "          [-1.2511e-01,  2.3177e-02,  8.5249e-02],\n",
      "          [ 5.6513e-02,  8.4848e-02,  3.5718e-02]],\n",
      "\n",
      "         [[ 1.0459e-01,  1.0574e-01, -1.3582e-01],\n",
      "          [-1.1801e-01,  7.4410e-02, -4.4244e-02],\n",
      "          [ 4.4392e-03,  5.7743e-02,  1.3211e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1918e-03,  1.3180e-01,  1.0549e-02],\n",
      "          [ 1.0425e-01,  9.3801e-02, -3.9847e-02],\n",
      "          [ 7.2785e-02, -2.3956e-02,  5.6948e-02]],\n",
      "\n",
      "         [[-9.9498e-02,  1.2769e-01, -1.2641e-01],\n",
      "          [-4.0938e-02,  2.4729e-02, -5.6910e-02],\n",
      "          [ 8.8620e-02,  6.2193e-02, -1.1465e-01]],\n",
      "\n",
      "         [[ 4.5967e-03, -4.6049e-02, -2.8795e-02],\n",
      "          [-3.9584e-02, -2.4666e-02,  9.2780e-02],\n",
      "          [-6.7388e-02,  9.6875e-02,  7.6784e-02]],\n",
      "\n",
      "         [[-9.0948e-02, -1.1449e-01,  1.2900e-02],\n",
      "          [ 1.2087e-01,  8.0292e-02,  1.2760e-01],\n",
      "          [ 1.3590e-02, -9.6915e-02, -9.0599e-02]],\n",
      "\n",
      "         [[-6.0499e-02, -1.3382e-01,  1.2016e-02],\n",
      "          [ 5.2914e-03,  2.0547e-02, -2.3914e-02],\n",
      "          [-1.0526e-01,  3.9519e-02,  2.2011e-02]],\n",
      "\n",
      "         [[-6.1565e-02, -2.6210e-02,  1.1832e-01],\n",
      "          [-8.5356e-03,  1.3306e-01, -1.2891e-03],\n",
      "          [-7.5447e-02, -1.1571e-01,  7.8853e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.6909e-02,  3.9060e-02, -9.3807e-02],\n",
      "          [ 6.5439e-02,  7.6383e-03,  7.7459e-03],\n",
      "          [-2.7197e-02,  6.3690e-02, -1.1036e-01]],\n",
      "\n",
      "         [[-9.2722e-02, -8.8486e-02,  1.5851e-02],\n",
      "          [-1.2650e-01,  1.0199e-01, -1.1642e-01],\n",
      "          [ 9.0232e-02,  1.0838e-01, -2.2651e-02]],\n",
      "\n",
      "         [[-5.9019e-02, -9.0102e-03,  1.0595e-01],\n",
      "          [ 6.1857e-02,  9.5379e-02,  1.7371e-02],\n",
      "          [-1.3550e-01, -1.3653e-02,  1.6942e-02]],\n",
      "\n",
      "         [[ 4.4270e-02, -3.9149e-02,  6.2454e-02],\n",
      "          [-5.7467e-02, -8.1775e-02,  8.6069e-02],\n",
      "          [ 4.3344e-04, -5.2045e-02,  6.0918e-02]],\n",
      "\n",
      "         [[ 4.9650e-03,  1.1619e-01,  8.5117e-02],\n",
      "          [ 2.4493e-02,  2.8724e-03, -4.1483e-02],\n",
      "          [ 3.9398e-02,  8.7198e-02,  8.1780e-02]],\n",
      "\n",
      "         [[-6.2325e-02, -2.5440e-02, -2.7482e-02],\n",
      "          [ 7.5109e-04,  5.9268e-02, -1.0010e-01],\n",
      "          [-2.5124e-03, -7.8110e-02, -2.0645e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.3453e-02, -4.0099e-02,  3.2645e-02],\n",
      "          [ 7.5214e-02,  6.7755e-02, -2.1913e-02],\n",
      "          [ 1.1288e-01,  7.9271e-02,  2.3079e-02]],\n",
      "\n",
      "         [[-4.9176e-02,  1.1108e-02, -2.3803e-02],\n",
      "          [-1.2959e-02, -1.1261e-01, -7.5128e-02],\n",
      "          [ 7.4065e-02,  4.8386e-02, -7.4789e-04]],\n",
      "\n",
      "         [[-1.0891e-01, -6.8436e-02, -1.2338e-01],\n",
      "          [ 1.0016e-02,  4.2075e-02, -1.2283e-01],\n",
      "          [-2.9729e-02, -2.7805e-02, -4.3249e-02]],\n",
      "\n",
      "         [[ 1.1464e-01,  6.9104e-02,  1.2568e-01],\n",
      "          [ 9.0481e-02, -1.2205e-01,  7.4543e-02],\n",
      "          [ 8.7165e-02, -9.4287e-04, -4.3647e-02]],\n",
      "\n",
      "         [[-8.8032e-03, -1.3074e-01,  1.5163e-02],\n",
      "          [ 1.3197e-01,  1.4914e-02,  1.0810e-01],\n",
      "          [ 3.7750e-02, -4.1016e-03, -6.6756e-02]],\n",
      "\n",
      "         [[ 1.1146e-01, -3.7604e-02,  2.2382e-02],\n",
      "          [ 2.7287e-02,  7.6805e-02,  4.5291e-03],\n",
      "          [-6.8483e-02,  1.2734e-01,  3.0697e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.3793e-02,  1.1335e-01, -1.2599e-01],\n",
      "          [ 4.2877e-02, -8.0965e-02, -2.6814e-03],\n",
      "          [ 9.4513e-02, -5.1010e-02, -4.8549e-02]],\n",
      "\n",
      "         [[-3.3184e-02, -9.5024e-02,  5.9454e-02],\n",
      "          [ 1.0854e-01,  8.3546e-02, -1.1718e-01],\n",
      "          [-7.0987e-02, -1.1690e-01,  1.1809e-01]],\n",
      "\n",
      "         [[-1.1482e-01, -1.3295e-01,  6.1759e-02],\n",
      "          [-8.8493e-02,  6.8631e-02,  5.1708e-02],\n",
      "          [-1.0450e-01, -9.1115e-02, -3.5364e-02]],\n",
      "\n",
      "         [[ 1.6028e-03,  6.6564e-02,  1.0990e-01],\n",
      "          [ 1.2182e-01,  1.2136e-01, -3.0066e-02],\n",
      "          [ 9.5324e-03, -5.4548e-02, -1.0005e-01]],\n",
      "\n",
      "         [[ 7.0638e-02, -3.4278e-02,  7.6404e-03],\n",
      "          [-5.5354e-02, -5.6394e-02, -1.1720e-01],\n",
      "          [ 2.9077e-02, -6.2167e-02,  9.7612e-02]],\n",
      "\n",
      "         [[ 2.1889e-02, -7.6750e-02, -1.1153e-01],\n",
      "          [ 1.4557e-02,  8.1876e-02, -7.0041e-02],\n",
      "          [-1.1593e-01,  7.9642e-02, -1.3373e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.5195e-02,  1.1422e-01, -3.2435e-02],\n",
      "          [-9.5339e-02,  1.3008e-01,  1.3011e-01],\n",
      "          [-1.1651e-01,  1.3181e-01, -7.7643e-02]],\n",
      "\n",
      "         [[ 7.8992e-02, -9.6642e-02, -1.1712e-01],\n",
      "          [-4.3344e-02,  1.0140e-01, -1.0057e-01],\n",
      "          [ 5.9015e-03, -3.8113e-02, -9.5792e-02]],\n",
      "\n",
      "         [[-5.8475e-03,  1.0714e-01, -4.2390e-02],\n",
      "          [-1.0822e-01, -6.5013e-02, -1.5230e-04],\n",
      "          [ 2.1861e-02,  1.1788e-01,  9.2432e-02]],\n",
      "\n",
      "         [[-1.0049e-01,  1.2141e-01, -6.1790e-03],\n",
      "          [ 8.5788e-03,  1.3222e-01, -9.9237e-02],\n",
      "          [ 3.0789e-02, -5.1441e-03,  1.2350e-01]],\n",
      "\n",
      "         [[-1.2278e-01,  9.9897e-02, -1.0967e-01],\n",
      "          [ 7.6005e-03,  9.0860e-03,  1.0494e-01],\n",
      "          [-1.2877e-01,  5.4546e-02,  2.8846e-02]],\n",
      "\n",
      "         [[-3.8720e-02, -9.2875e-02,  1.1733e-01],\n",
      "          [ 6.0636e-02, -7.7112e-02,  1.1199e-01],\n",
      "          [ 9.6891e-02, -5.3565e-02, -1.6169e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0744e-01,  3.4238e-02,  7.4385e-02],\n",
      "          [ 2.7694e-02, -4.5642e-02,  1.3281e-01],\n",
      "          [ 2.3671e-02, -5.3262e-02,  4.1174e-02]],\n",
      "\n",
      "         [[-1.3123e-01, -8.5280e-02, -8.4176e-02],\n",
      "          [ 9.1786e-02,  7.2301e-02,  8.9094e-02],\n",
      "          [-1.3452e-01, -1.0434e-02, -1.8962e-02]],\n",
      "\n",
      "         [[-1.3486e-01,  1.0305e-01,  1.0375e-01],\n",
      "          [-8.9394e-02,  6.6673e-02, -2.2194e-02],\n",
      "          [-1.1189e-01,  1.0829e-01, -3.5811e-02]],\n",
      "\n",
      "         [[ 7.3113e-02, -8.9906e-02,  7.5191e-02],\n",
      "          [-8.6920e-02,  1.0708e-01, -6.9574e-03],\n",
      "          [-5.8217e-02, -8.2323e-02, -1.1240e-01]],\n",
      "\n",
      "         [[ 1.2623e-01, -9.0077e-02,  1.2423e-01],\n",
      "          [ 9.3627e-02,  8.5618e-02,  3.0205e-03],\n",
      "          [-4.9404e-02, -1.2568e-01,  3.1381e-02]],\n",
      "\n",
      "         [[ 1.2821e-01,  5.3871e-02, -4.7765e-02],\n",
      "          [ 6.3658e-02, -4.2663e-02, -5.8661e-02],\n",
      "          [-4.2707e-02, -1.1585e-01, -8.7103e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.2182e-02, -2.8522e-02, -5.4851e-02],\n",
      "          [ 2.4556e-02, -1.2028e-01,  4.4367e-02],\n",
      "          [ 1.0209e-02,  1.6772e-02,  8.1545e-02]],\n",
      "\n",
      "         [[-1.3242e-01,  2.1646e-02,  1.5462e-03],\n",
      "          [-4.8784e-02, -1.0082e-01,  1.8332e-02],\n",
      "          [-3.3083e-02, -1.2711e-01, -1.1806e-01]],\n",
      "\n",
      "         [[-7.5662e-02,  4.6688e-02,  9.7078e-02],\n",
      "          [-6.8301e-02,  5.7341e-02,  5.5128e-02],\n",
      "          [ 1.3082e-01, -4.2979e-02,  1.1702e-01]],\n",
      "\n",
      "         [[-7.4338e-02, -9.9759e-03,  1.0680e-01],\n",
      "          [ 4.3134e-02, -4.8134e-02,  2.0418e-02],\n",
      "          [ 4.0004e-02,  8.5882e-02,  9.8419e-02]],\n",
      "\n",
      "         [[-2.9572e-02,  1.7032e-02,  8.5470e-02],\n",
      "          [-7.7651e-02,  1.1904e-01, -1.0325e-01],\n",
      "          [ 4.3043e-02,  8.8012e-02, -4.4548e-02]],\n",
      "\n",
      "         [[ 1.0970e-02, -1.0825e-01,  4.7473e-02],\n",
      "          [ 7.9896e-02, -6.5214e-02, -1.3134e-01],\n",
      "          [ 2.2980e-02, -5.9097e-02,  6.1828e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.7132e-02,  3.2953e-03,  1.0738e-01],\n",
      "          [-4.4675e-02, -5.4328e-02,  6.6646e-02],\n",
      "          [-5.4924e-02, -9.4565e-02, -8.5028e-02]],\n",
      "\n",
      "         [[ 1.1111e-01, -7.7166e-02,  5.7061e-02],\n",
      "          [-1.2454e-01, -5.0340e-03,  9.2883e-03],\n",
      "          [ 1.2837e-01,  3.5518e-02,  9.7971e-02]],\n",
      "\n",
      "         [[ 5.8440e-02, -4.3541e-02, -1.3022e-01],\n",
      "          [ 4.2318e-02,  2.5222e-02, -7.8137e-02],\n",
      "          [-1.1095e-01,  7.3925e-02, -1.0908e-01]],\n",
      "\n",
      "         [[-3.8549e-02, -7.6870e-03,  1.8438e-02],\n",
      "          [ 7.4065e-02, -2.2828e-03,  8.1107e-02],\n",
      "          [-1.2628e-01,  9.1600e-02, -7.0469e-02]],\n",
      "\n",
      "         [[-1.0802e-02, -6.3616e-03,  5.2489e-02],\n",
      "          [ 7.6817e-02,  1.0734e-01,  1.0161e-01],\n",
      "          [-8.4139e-02, -2.9495e-02,  1.2632e-01]],\n",
      "\n",
      "         [[ 8.1366e-02,  1.0244e-01, -1.1001e-01],\n",
      "          [ 1.3415e-02,  1.3241e-01, -6.2273e-02],\n",
      "          [ 2.8376e-02,  1.2642e-01,  1.0906e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4921e-02, -5.4131e-02,  8.7298e-02],\n",
      "          [ 6.8505e-02, -5.5965e-02,  3.4689e-02],\n",
      "          [-4.8715e-02, -3.4022e-02,  5.6294e-02]],\n",
      "\n",
      "         [[-4.2181e-02,  6.7443e-02,  1.7751e-02],\n",
      "          [ 9.5516e-02,  1.1177e-01, -8.6196e-02],\n",
      "          [ 1.0385e-01,  1.0272e-01, -1.1239e-01]],\n",
      "\n",
      "         [[ 2.3047e-02, -1.2399e-01,  9.7846e-03],\n",
      "          [ 1.7884e-02, -9.0126e-02,  5.1976e-02],\n",
      "          [ 7.3294e-02, -1.9591e-02,  1.0566e-01]],\n",
      "\n",
      "         [[ 7.5434e-02, -1.1355e-02,  1.2924e-01],\n",
      "          [ 1.0471e-01,  9.3373e-02,  2.3739e-02],\n",
      "          [-6.7523e-02, -1.1686e-02, -1.2951e-01]],\n",
      "\n",
      "         [[ 1.6438e-02, -7.8844e-02,  6.0647e-02],\n",
      "          [-2.2068e-02,  1.3690e-02,  9.1372e-02],\n",
      "          [ 9.6069e-02, -1.0473e-01, -1.1050e-01]],\n",
      "\n",
      "         [[ 1.2808e-01,  7.0273e-03,  1.1791e-01],\n",
      "          [ 1.0151e-03,  8.1391e-02,  3.6374e-02],\n",
      "          [-8.5775e-02, -9.4650e-02,  1.3066e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1799e-01, -5.4219e-02, -5.5562e-02],\n",
      "          [-1.0526e-01, -3.4155e-02,  2.7901e-02],\n",
      "          [-6.9943e-02,  6.2890e-02, -1.5803e-03]],\n",
      "\n",
      "         [[-1.7576e-02,  4.8838e-02, -1.7353e-02],\n",
      "          [ 8.0464e-02,  3.1444e-02,  1.0291e-01],\n",
      "          [-7.2035e-02,  6.2943e-02, -1.1025e-01]],\n",
      "\n",
      "         [[ 3.9305e-04,  8.6846e-02, -7.4452e-02],\n",
      "          [ 1.0872e-01, -9.2204e-02,  1.0704e-01],\n",
      "          [-1.3226e-02, -7.8300e-02, -9.4015e-02]],\n",
      "\n",
      "         [[ 1.1984e-01,  1.2610e-01,  1.3561e-01],\n",
      "          [ 7.6883e-02,  1.0076e-01, -1.2180e-01],\n",
      "          [-1.5435e-02,  8.6857e-02,  1.1221e-01]],\n",
      "\n",
      "         [[ 6.9361e-02, -2.2070e-02, -4.5668e-02],\n",
      "          [-6.4436e-02, -1.2916e-01, -1.3169e-01],\n",
      "          [-7.8114e-02, -1.2028e-01,  2.5946e-02]],\n",
      "\n",
      "         [[ 1.1992e-01, -1.2606e-01, -5.7646e-02],\n",
      "          [ 1.2112e-01, -7.0234e-03, -1.3429e-01],\n",
      "          [ 1.1821e-01, -1.3152e-01, -1.2092e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1273e-01, -2.4621e-02, -1.2487e-01],\n",
      "          [ 1.6906e-02, -6.9624e-02, -7.1765e-03],\n",
      "          [ 8.6919e-02, -4.8128e-02, -1.2750e-01]],\n",
      "\n",
      "         [[-8.1789e-02, -2.1388e-02, -1.0144e-01],\n",
      "          [-9.0128e-02,  8.7469e-02,  3.4721e-02],\n",
      "          [ 8.4964e-02,  5.8246e-02,  3.0506e-02]],\n",
      "\n",
      "         [[ 1.1100e-01,  4.5000e-02, -7.3157e-03],\n",
      "          [ 1.0971e-01, -1.2347e-01,  2.0028e-02],\n",
      "          [-4.9513e-03,  2.5999e-02,  9.2561e-02]],\n",
      "\n",
      "         [[-1.1507e-01, -2.0682e-02,  5.9371e-02],\n",
      "          [ 1.1539e-02,  1.7391e-02, -5.5911e-02],\n",
      "          [-9.2249e-02,  1.3016e-01, -1.3173e-01]],\n",
      "\n",
      "         [[-6.0679e-02,  4.8828e-02, -5.6301e-02],\n",
      "          [ 1.3162e-02, -1.0461e-01, -3.5429e-02],\n",
      "          [-8.3239e-02,  2.8929e-02, -1.2014e-01]],\n",
      "\n",
      "         [[ 1.0810e-01,  6.4170e-02, -4.9410e-02],\n",
      "          [ 1.0521e-01, -6.0802e-02,  1.2578e-01],\n",
      "          [-6.2138e-02,  8.9895e-03,  1.2586e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4895e-02,  5.7773e-02,  1.3115e-02],\n",
      "          [-1.3504e-02, -1.3149e-01,  4.8359e-02],\n",
      "          [-4.9536e-02, -8.4786e-02, -1.2712e-02]],\n",
      "\n",
      "         [[-3.1980e-02, -1.2268e-01, -4.1647e-02],\n",
      "          [ 6.3903e-02,  1.0695e-01, -2.3262e-02],\n",
      "          [-1.1379e-01, -2.4445e-03, -9.5893e-02]],\n",
      "\n",
      "         [[ 8.1406e-02, -7.7034e-02,  1.7955e-02],\n",
      "          [-6.7540e-02,  4.8007e-02,  3.4733e-02],\n",
      "          [ 9.9972e-03,  8.8992e-03, -6.4505e-02]],\n",
      "\n",
      "         [[-5.0119e-04,  8.7865e-02, -1.2194e-02],\n",
      "          [ 3.8657e-02, -6.3013e-02, -1.2475e-01],\n",
      "          [-8.6216e-02,  1.0607e-01,  9.6889e-02]],\n",
      "\n",
      "         [[ 5.9806e-02, -6.0633e-02, -8.4820e-02],\n",
      "          [-2.0038e-02, -9.3231e-02,  8.1494e-05],\n",
      "          [-1.3900e-02,  6.6057e-02,  1.1314e-01]],\n",
      "\n",
      "         [[ 1.2969e-01, -9.7096e-02, -9.7851e-02],\n",
      "          [-1.2052e-01,  2.0044e-03,  5.8285e-03],\n",
      "          [ 9.1590e-02,  6.9720e-02,  1.0445e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2404e-01, -8.8147e-02, -1.2754e-03],\n",
      "          [-3.5975e-02,  9.6689e-02, -4.8718e-02],\n",
      "          [-1.0563e-01,  1.2693e-01, -4.5545e-02]],\n",
      "\n",
      "         [[ 3.2409e-02,  1.8872e-02,  4.2502e-02],\n",
      "          [-9.1661e-03,  6.5486e-02, -8.2895e-02],\n",
      "          [ 8.2432e-02, -6.7592e-02,  8.8626e-02]],\n",
      "\n",
      "         [[ 5.5521e-03, -1.7633e-02,  5.4801e-02],\n",
      "          [ 1.1845e-01,  5.9815e-02, -1.1503e-01],\n",
      "          [ 1.1783e-01, -1.0862e-01,  1.1228e-01]],\n",
      "\n",
      "         [[ 6.0531e-02, -1.1861e-01, -6.1061e-03],\n",
      "          [ 6.4904e-03,  9.4382e-02, -3.1648e-02],\n",
      "          [ 1.3132e-01,  3.8846e-02,  7.1298e-02]],\n",
      "\n",
      "         [[ 5.0785e-02, -1.1205e-01, -7.9024e-02],\n",
      "          [ 1.1521e-01,  3.7468e-03,  9.1311e-02],\n",
      "          [ 1.1129e-01, -7.5454e-02,  7.4328e-02]],\n",
      "\n",
      "         [[-3.4404e-03,  6.6967e-02,  1.1643e-01],\n",
      "          [ 1.2996e-01,  7.9567e-02, -1.3295e-02],\n",
      "          [ 6.3314e-03,  8.0059e-02,  7.6104e-02]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1231,  0.0273,  0.1166, -0.0932, -0.0142, -0.0035, -0.0321, -0.0330,\n",
      "        -0.0702, -0.0736,  0.1020,  0.0681,  0.0243,  0.0445,  0.1243,  0.1129],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0070, -0.0388,  0.0229,  ...,  0.0376,  0.0324,  0.0386],\n",
      "        [ 0.0326, -0.0162,  0.0027,  ...,  0.0137, -0.0327,  0.0328],\n",
      "        [-0.0263,  0.0081,  0.0112,  ..., -0.0192, -0.0413, -0.0398],\n",
      "        ...,\n",
      "        [-0.0223,  0.0201, -0.0180,  ..., -0.0060,  0.0238, -0.0081],\n",
      "        [-0.0088, -0.0247,  0.0100,  ..., -0.0340, -0.0114,  0.0121],\n",
      "        [-0.0200, -0.0235,  0.0307,  ...,  0.0416,  0.0302, -0.0240]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0184,  0.0069,  0.0265,  0.0200,  0.0402,  0.0067,  0.0412, -0.0077,\n",
      "        -0.0053,  0.0139,  0.0224, -0.0270, -0.0348, -0.0110,  0.0239, -0.0192,\n",
      "        -0.0183, -0.0059, -0.0371,  0.0364, -0.0057,  0.0173,  0.0362, -0.0080,\n",
      "        -0.0335,  0.0015, -0.0278, -0.0225,  0.0054,  0.0414, -0.0402,  0.0410,\n",
      "         0.0355, -0.0381,  0.0024,  0.0351,  0.0173, -0.0207, -0.0167,  0.0330,\n",
      "        -0.0221, -0.0314, -0.0254,  0.0180,  0.0358, -0.0289, -0.0145,  0.0238,\n",
      "        -0.0316,  0.0410,  0.0067,  0.0398, -0.0140, -0.0211, -0.0278, -0.0319,\n",
      "         0.0023,  0.0205, -0.0217,  0.0260,  0.0305, -0.0288,  0.0097,  0.0149,\n",
      "        -0.0143, -0.0186,  0.0038, -0.0279, -0.0121,  0.0125, -0.0105, -0.0247,\n",
      "        -0.0007,  0.0241, -0.0249,  0.0279,  0.0113,  0.0391,  0.0066,  0.0068,\n",
      "         0.0084, -0.0391, -0.0404,  0.0195,  0.0165,  0.0215,  0.0211,  0.0186,\n",
      "         0.0393,  0.0219,  0.0071,  0.0350,  0.0030, -0.0359, -0.0413,  0.0242,\n",
      "        -0.0329,  0.0101,  0.0400,  0.0364,  0.0412,  0.0267, -0.0022,  0.0258,\n",
      "        -0.0007, -0.0040, -0.0063,  0.0188,  0.0085,  0.0028, -0.0028, -0.0124,\n",
      "         0.0300,  0.0020,  0.0133,  0.0328,  0.0062,  0.0323,  0.0192,  0.0321],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0617,  0.0899, -0.0607,  ...,  0.0056,  0.0822,  0.0209],\n",
      "        [ 0.0891, -0.0365,  0.0388,  ..., -0.0211,  0.0596, -0.0822],\n",
      "        [ 0.0872, -0.0783, -0.0476,  ..., -0.0861,  0.0304, -0.0474],\n",
      "        ...,\n",
      "        [-0.0676,  0.0737, -0.0745,  ..., -0.0509, -0.0482, -0.0281],\n",
      "        [-0.0699,  0.0554,  0.0575,  ..., -0.0836,  0.0297, -0.0875],\n",
      "        [ 0.0752, -0.0106, -0.0433,  ..., -0.0102, -0.0131,  0.0314]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0339,  0.0364,  0.0571,  0.0144,  0.0340,  0.0233,  0.0114,  0.0908,\n",
      "         0.0629,  0.0700, -0.0465,  0.0902,  0.0415, -0.0273,  0.0894, -0.0524,\n",
      "         0.0541, -0.0407,  0.0797,  0.0016,  0.0122,  0.0684, -0.0643, -0.0412,\n",
      "        -0.0034, -0.0161,  0.0616, -0.0757,  0.0279, -0.0761,  0.0637, -0.0622,\n",
      "         0.0230,  0.0782, -0.0378, -0.0675,  0.0427, -0.0812,  0.0432, -0.0832,\n",
      "        -0.0288,  0.0234, -0.0531,  0.0876, -0.0128, -0.0605, -0.0044,  0.0781,\n",
      "        -0.0387,  0.0508, -0.0693,  0.0878,  0.0258, -0.0245, -0.0083,  0.0191,\n",
      "         0.0598, -0.0535, -0.0880, -0.0786, -0.0399, -0.0236,  0.0860, -0.0761,\n",
      "         0.0630, -0.0493,  0.0328, -0.0716, -0.0071,  0.0867,  0.0711, -0.0892,\n",
      "        -0.0340,  0.0641,  0.0736, -0.0544, -0.0817,  0.0452, -0.0647,  0.0350,\n",
      "         0.0885,  0.0057,  0.0478, -0.0807], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0435, -0.0130,  0.0544, -0.1010, -0.0023, -0.0387, -0.0413,  0.0490,\n",
      "         -0.0425,  0.0413,  0.0810,  0.0699, -0.0254,  0.1082,  0.0891, -0.0697,\n",
      "          0.0772, -0.0462,  0.0178,  0.0080, -0.0295, -0.0836,  0.0057, -0.0190,\n",
      "         -0.0971,  0.0629, -0.0460, -0.0292, -0.0554, -0.0794, -0.0326, -0.0554,\n",
      "         -0.0436,  0.0571,  0.0567, -0.0499, -0.0036, -0.0254,  0.0091, -0.0345,\n",
      "          0.0437,  0.0781, -0.0399, -0.1050,  0.0614,  0.0643,  0.0809, -0.0314,\n",
      "         -0.0910, -0.0133,  0.0195, -0.0280, -0.0380, -0.0332,  0.0988, -0.0758,\n",
      "          0.0226, -0.0172,  0.0003,  0.1084,  0.1070, -0.0514,  0.0850,  0.0734,\n",
      "          0.0039,  0.0933, -0.0740, -0.0281, -0.0544, -0.1025,  0.0688,  0.0964,\n",
      "          0.1009, -0.0076, -0.0124, -0.0023,  0.0016,  0.0194, -0.0897, -0.0660,\n",
      "         -0.0434,  0.0479, -0.0019,  0.0044],\n",
      "        [ 0.0580,  0.0340, -0.0773, -0.0629,  0.0347, -0.0089, -0.0756, -0.0951,\n",
      "          0.0881,  0.0952, -0.0004,  0.0367,  0.0678,  0.0805,  0.1062,  0.0161,\n",
      "         -0.1029, -0.0568,  0.0939, -0.0314,  0.0185, -0.0100,  0.0647,  0.1079,\n",
      "         -0.0976,  0.0746, -0.0227, -0.0071,  0.0284, -0.0072,  0.0507, -0.0354,\n",
      "         -0.0989, -0.0733, -0.0593,  0.0561, -0.0474,  0.1057, -0.0337, -0.0073,\n",
      "          0.1013, -0.0880,  0.0173, -0.0779, -0.0081, -0.0282, -0.0820, -0.0480,\n",
      "          0.0127,  0.0561,  0.0350,  0.0267, -0.0862,  0.0333,  0.0779, -0.1071,\n",
      "         -0.0422, -0.0497, -0.0225, -0.0828,  0.1038, -0.0024,  0.0814, -0.0987,\n",
      "         -0.0435,  0.0014,  0.0214,  0.0558,  0.0691, -0.0448,  0.0215, -0.0094,\n",
      "          0.0768,  0.0868,  0.0008,  0.0652, -0.0618, -0.0212, -0.0889,  0.0761,\n",
      "         -0.0571, -0.0542,  0.0715, -0.0395],\n",
      "        [-0.0521, -0.0270, -0.0620,  0.0150,  0.0482,  0.0791, -0.0959, -0.0861,\n",
      "         -0.0021,  0.0405, -0.0929,  0.0077, -0.0564, -0.0779,  0.0431,  0.0916,\n",
      "         -0.0223, -0.0873,  0.0221, -0.0198,  0.0047, -0.0842, -0.1066,  0.1084,\n",
      "         -0.1004, -0.0713,  0.0842,  0.1085,  0.0566,  0.0086,  0.1082, -0.1086,\n",
      "          0.0096, -0.0596, -0.0475,  0.0863, -0.0311, -0.0051,  0.0964,  0.0417,\n",
      "          0.0906, -0.0609, -0.0724, -0.0220,  0.0609,  0.1041, -0.0304, -0.0795,\n",
      "         -0.0731,  0.0168, -0.0836, -0.0714, -0.1023,  0.0202, -0.0121,  0.0699,\n",
      "          0.0771, -0.0225, -0.0732, -0.0522, -0.0006, -0.0200, -0.0473,  0.0815,\n",
      "         -0.0149,  0.0647,  0.0430, -0.0993, -0.0801,  0.0005, -0.0966, -0.0373,\n",
      "          0.0232,  0.0026,  0.0577, -0.0133,  0.0999,  0.0705, -0.0871, -0.0633,\n",
      "         -0.0779,  0.0013, -0.0893, -0.0480],\n",
      "        [ 0.0131,  0.0664,  0.0610, -0.0498,  0.0064,  0.0382,  0.0640,  0.0845,\n",
      "         -0.1085,  0.0679,  0.0133, -0.0194, -0.0506,  0.0214,  0.0030, -0.1086,\n",
      "          0.0021,  0.0439, -0.0106,  0.0347, -0.0866,  0.0664,  0.0600,  0.0089,\n",
      "          0.0501,  0.0327,  0.0884, -0.0096,  0.0441,  0.1075, -0.0579, -0.0013,\n",
      "         -0.0239,  0.0581,  0.0547,  0.0516,  0.0537,  0.0202,  0.0982, -0.1020,\n",
      "          0.0555, -0.0605,  0.0353,  0.1074,  0.0752, -0.0386,  0.0266, -0.0646,\n",
      "         -0.0065, -0.0312, -0.0617, -0.0279,  0.1033,  0.0344,  0.0781, -0.0988,\n",
      "         -0.0104,  0.0796, -0.0940,  0.0903,  0.0079,  0.1016,  0.0435,  0.1031,\n",
      "         -0.1073,  0.0694, -0.0640, -0.0363, -0.0698,  0.0798,  0.0062, -0.0538,\n",
      "         -0.0952,  0.0668,  0.0350, -0.1017, -0.0326, -0.0600,  0.0285, -0.0364,\n",
      "         -0.0900, -0.1050, -0.0507,  0.0343],\n",
      "        [-0.0592, -0.0605, -0.0415,  0.1046, -0.0346, -0.0735,  0.1027,  0.0364,\n",
      "         -0.0820, -0.0850,  0.0034, -0.0564,  0.0167,  0.0226, -0.0365, -0.0497,\n",
      "         -0.0193, -0.0279,  0.0269, -0.0085,  0.1036, -0.0453,  0.0783,  0.0919,\n",
      "          0.0703,  0.0752, -0.0842, -0.0816,  0.1004,  0.0029,  0.0536, -0.0629,\n",
      "         -0.0247,  0.0994,  0.0756,  0.0373,  0.0206, -0.0826,  0.0363,  0.1055,\n",
      "         -0.0933,  0.0910, -0.0595,  0.0785,  0.0586,  0.0043, -0.1005, -0.0945,\n",
      "         -0.0697,  0.0566,  0.0977, -0.0949,  0.0316,  0.0688, -0.0403, -0.0307,\n",
      "         -0.0186,  0.0070, -0.0250, -0.0556, -0.0518, -0.0936,  0.0573, -0.0880,\n",
      "         -0.0604,  0.0345,  0.0350,  0.0938, -0.0026, -0.0739,  0.0761,  0.0352,\n",
      "         -0.0761, -0.1039,  0.0433, -0.0513, -0.0925,  0.0842,  0.0983, -0.1078,\n",
      "         -0.0834, -0.0949,  0.0633, -0.0438],\n",
      "        [-0.0188, -0.0518,  0.0901, -0.0471, -0.0191, -0.0439, -0.0767, -0.0174,\n",
      "          0.0788,  0.0962, -0.1067, -0.0637, -0.0603,  0.0280,  0.0554, -0.0374,\n",
      "          0.0956,  0.1039,  0.0956,  0.0159, -0.0777,  0.0703,  0.0336,  0.0304,\n",
      "          0.0352, -0.0706,  0.0394,  0.0155, -0.0687,  0.0142, -0.0931, -0.1014,\n",
      "         -0.0859,  0.0452,  0.0801,  0.0920,  0.0607, -0.0879, -0.0633, -0.0593,\n",
      "         -0.0976, -0.0952,  0.0699, -0.0601,  0.0118, -0.0593,  0.0012,  0.0252,\n",
      "         -0.0009, -0.0956, -0.1071,  0.1064, -0.0192,  0.0330, -0.0598, -0.0826,\n",
      "          0.0715, -0.0538,  0.0340,  0.0026,  0.0276,  0.0378,  0.0626, -0.0592,\n",
      "         -0.0834,  0.0167,  0.0518, -0.0271, -0.0235, -0.0724,  0.0162, -0.0404,\n",
      "         -0.0435,  0.0856,  0.0178, -0.0279, -0.0423,  0.0799,  0.0746,  0.0574,\n",
      "         -0.0338, -0.0032, -0.0612,  0.0550],\n",
      "        [-0.0296,  0.0676,  0.0068,  0.0170,  0.0992, -0.0761,  0.0393,  0.0523,\n",
      "          0.0074, -0.0999,  0.0856,  0.0015,  0.0842, -0.0522,  0.0993,  0.0037,\n",
      "         -0.0773,  0.0323, -0.0910,  0.0693,  0.0692,  0.0211, -0.0954,  0.0162,\n",
      "          0.0320, -0.0846, -0.0577, -0.0092, -0.1019,  0.0763,  0.0114,  0.0657,\n",
      "          0.0612,  0.0505, -0.0590, -0.0887, -0.0524, -0.0751,  0.0664, -0.1020,\n",
      "          0.0681,  0.0737, -0.0564, -0.0753,  0.0625, -0.0492,  0.0081, -0.0236,\n",
      "         -0.0284, -0.0091, -0.0486, -0.0731, -0.0708,  0.0261, -0.0295, -0.0143,\n",
      "         -0.0178,  0.0914, -0.0958, -0.0077, -0.0548,  0.0764,  0.0463,  0.0431,\n",
      "         -0.0336,  0.0202, -0.0168,  0.0915,  0.0312, -0.0913,  0.0052,  0.0498,\n",
      "         -0.0551,  0.0784,  0.0665, -0.0995,  0.0875, -0.0305,  0.0754, -0.0851,\n",
      "         -0.1034, -0.0244,  0.0763, -0.0104],\n",
      "        [-0.0195, -0.1030,  0.0749, -0.0913,  0.0757, -0.0258,  0.0884, -0.0098,\n",
      "         -0.0589, -0.0011,  0.0353,  0.0701, -0.0971,  0.0459,  0.0731, -0.1073,\n",
      "         -0.0979, -0.0976, -0.0554, -0.1089, -0.0483,  0.1029, -0.0030,  0.0835,\n",
      "          0.0504,  0.0326,  0.0969,  0.0396,  0.0199,  0.0503,  0.0229, -0.0808,\n",
      "         -0.0449, -0.0941, -0.0376,  0.0493,  0.0592,  0.0324, -0.0557,  0.0780,\n",
      "          0.0982, -0.1065,  0.0031, -0.0031, -0.0152, -0.0942,  0.0048,  0.0457,\n",
      "         -0.1084, -0.0532,  0.0841,  0.0954,  0.0166, -0.0550, -0.0539,  0.0043,\n",
      "         -0.0330,  0.0092,  0.0472, -0.0985,  0.0701,  0.0102, -0.0007,  0.0222,\n",
      "         -0.0598,  0.0855,  0.0999,  0.0002,  0.1085, -0.1028, -0.0461, -0.0199,\n",
      "         -0.0090,  0.0562, -0.0960, -0.0151, -0.0202, -0.0141, -0.0688, -0.0268,\n",
      "         -0.0308,  0.0276,  0.1064, -0.0958],\n",
      "        [-0.0377, -0.0225, -0.0922, -0.0521, -0.0300, -0.0352, -0.0463,  0.0952,\n",
      "          0.0812, -0.0233,  0.0418,  0.0370, -0.0402, -0.0611, -0.1000, -0.0526,\n",
      "          0.1085, -0.0825, -0.0671, -0.0006,  0.0037,  0.0728, -0.0533,  0.0989,\n",
      "          0.0305, -0.0755,  0.0706, -0.0633,  0.0242, -0.0882, -0.0344,  0.0459,\n",
      "         -0.0465,  0.0418,  0.0815,  0.0936, -0.0868, -0.1023, -0.0919,  0.0542,\n",
      "         -0.0729, -0.0560, -0.0218, -0.0023, -0.0414,  0.0855, -0.0027,  0.1070,\n",
      "         -0.0952,  0.0182,  0.0357,  0.0778,  0.0820, -0.1027,  0.0796, -0.0067,\n",
      "          0.0635, -0.0677, -0.0991, -0.0859, -0.0063,  0.1068,  0.0447,  0.0779,\n",
      "          0.1008,  0.0373, -0.0237,  0.0191,  0.0084,  0.0884,  0.0862,  0.0729,\n",
      "         -0.0248, -0.0260, -0.0056, -0.0381,  0.1070, -0.0540,  0.0900,  0.1043,\n",
      "          0.1013,  0.0493,  0.0166,  0.0276],\n",
      "        [ 0.0359, -0.0672, -0.0839, -0.0548, -0.0944,  0.0477,  0.0599, -0.0612,\n",
      "          0.1024,  0.0053, -0.0583, -0.0070, -0.1079,  0.0812, -0.0838, -0.0811,\n",
      "          0.0203,  0.0826, -0.0025,  0.0400, -0.0433,  0.0659, -0.0948, -0.0138,\n",
      "         -0.0847, -0.0565,  0.0529,  0.0278, -0.0981,  0.0055,  0.0384, -0.0500,\n",
      "          0.0138,  0.0421, -0.0589,  0.0913, -0.0143, -0.0850,  0.1075, -0.0702,\n",
      "          0.0279,  0.0450,  0.0954,  0.0759, -0.0886,  0.1002, -0.0690, -0.0704,\n",
      "          0.0280,  0.0735, -0.0046,  0.0248,  0.0708, -0.0725,  0.1028, -0.0536,\n",
      "          0.0934,  0.0457,  0.0987,  0.0763,  0.0295, -0.0773, -0.0761, -0.0476,\n",
      "         -0.0124,  0.0456,  0.0325, -0.0072,  0.1009, -0.0444, -0.0299, -0.0323,\n",
      "          0.0379, -0.0340,  0.0926, -0.1051, -0.0103,  0.0954, -0.1042,  0.0684,\n",
      "         -0.0836,  0.0543,  0.0907,  0.0480]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0304,  0.0433,  0.0242,  0.0840,  0.0423, -0.0890,  0.0662, -0.0973,\n",
      "        -0.0682,  0.0387], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 3, 3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 3, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[3].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 576])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[4].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[5].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84, 120])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[6].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[7].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 84])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[8].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[9].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0670,  0.0194, -0.0648,  0.1775,  0.0317, -0.0163,  0.0256, -0.1010,\n",
      "         -0.0276,  0.0469]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(1,1,32,32)\n",
    "out = net(inp)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2896, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(inp)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1,-1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output,target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x0000023B969FBDC8>\n",
      "<AddmmBackward object at 0x0000023B969FBE48>\n",
      "<AccumulateGrad object at 0x0000023B969FBDC8>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)\n",
    "print(loss.grad_fn.next_functions[0][0]) #linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) #relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "#in your training loop\n",
    "optimizer.zero_grad()\n",
    "output = net(inp)\n",
    "loss = criterion(output,target)\n",
    "loss.backward()\n",
    "optimizer.step() #updates the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2671, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.01\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
